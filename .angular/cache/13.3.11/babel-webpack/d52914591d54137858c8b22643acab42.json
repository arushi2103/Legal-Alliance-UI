{"ast":null,"code":"\"use strict\";\n\nvar _asyncToGenerator = require(\"D:\\\\dev-projects\\\\APEX\\\\Legalalliance\\\\node_modules\\\\@babel\\\\runtime\\\\helpers\\\\asyncToGenerator.js\").default;\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.GridFSBucketWriteStream = void 0;\n\nconst stream_1 = require(\"stream\");\n\nconst bson_1 = require(\"../bson\");\n\nconst error_1 = require(\"../error\");\n\nconst write_concern_1 = require(\"./../write_concern\");\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n * @public\n */\n\n\nclass GridFSBucketWriteStream extends stream_1.Writable {\n  /**\n   * @param bucket - Handle for this stream's corresponding bucket\n   * @param filename - The value of the 'filename' key in the files doc\n   * @param options - Optional settings.\n   * @internal\n   */\n  constructor(bucket, filename, options) {\n    super();\n    options = options ?? {};\n    this.bucket = bucket;\n    this.chunks = bucket.s._chunksCollection;\n    this.filename = filename;\n    this.files = bucket.s._filesCollection;\n    this.options = options;\n    this.writeConcern = write_concern_1.WriteConcern.fromOptions(options) || bucket.s.options.writeConcern; // Signals the write is all done\n\n    this.done = false;\n    this.id = options.id ? options.id : new bson_1.ObjectId(); // properly inherit the default chunksize from parent\n\n    this.chunkSizeBytes = options.chunkSizeBytes || this.bucket.s.options.chunkSizeBytes;\n    this.bufToStore = Buffer.alloc(this.chunkSizeBytes);\n    this.length = 0;\n    this.n = 0;\n    this.pos = 0;\n    this.state = {\n      streamEnd: false,\n      outstandingRequests: 0,\n      errored: false,\n      aborted: false\n    };\n\n    if (!this.bucket.s.calledOpenUploadStream) {\n      this.bucket.s.calledOpenUploadStream = true;\n      checkIndexes(this).then(() => {\n        this.bucket.s.checkedIndexes = true;\n        this.bucket.emit('index');\n      }, () => null);\n    }\n  }\n\n  write(chunk, encodingOrCallback, callback) {\n    const encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\n    callback = typeof encodingOrCallback === 'function' ? encodingOrCallback : callback;\n    return waitForIndexes(this, () => doWrite(this, chunk, encoding, callback));\n  }\n  /**\n   * Places this write stream into an aborted state (all future writes fail)\n   * and deletes all chunks that have already been written.\n   */\n\n\n  abort() {\n    var _this = this;\n\n    return _asyncToGenerator(function* () {\n      if (_this.state.streamEnd) {\n        // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n        throw new error_1.MongoAPIError('Cannot abort a stream that has already completed');\n      }\n\n      if (_this.state.aborted) {\n        // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n        throw new error_1.MongoAPIError('Cannot call abort() on a stream twice');\n      }\n\n      _this.state.aborted = true;\n      yield _this.chunks.deleteMany({\n        files_id: _this.id\n      });\n    })();\n  }\n\n  end(chunkOrCallback, encodingOrCallback, callback) {\n    const chunk = typeof chunkOrCallback === 'function' ? undefined : chunkOrCallback;\n    const encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\n    callback = typeof chunkOrCallback === 'function' ? chunkOrCallback : typeof encodingOrCallback === 'function' ? encodingOrCallback : callback;\n    if (this.state.streamEnd || checkAborted(this, callback)) return this;\n    this.state.streamEnd = true;\n\n    if (callback) {\n      this.once(GridFSBucketWriteStream.FINISH, result => {\n        if (callback) callback(undefined, result);\n      });\n    }\n\n    if (!chunk) {\n      waitForIndexes(this, () => !!writeRemnant(this));\n      return this;\n    }\n\n    this.write(chunk, encoding, () => {\n      writeRemnant(this);\n    });\n    return this;\n  }\n\n}\n\nexports.GridFSBucketWriteStream = GridFSBucketWriteStream;\n/** @event */\n\nGridFSBucketWriteStream.CLOSE = 'close';\n/** @event */\n\nGridFSBucketWriteStream.ERROR = 'error';\n/**\n * `end()` was called and the write stream successfully wrote the file metadata and all the chunks to MongoDB.\n * @event\n */\n\nGridFSBucketWriteStream.FINISH = 'finish';\n\nfunction __handleError(stream, error, callback) {\n  if (stream.state.errored) {\n    return;\n  }\n\n  stream.state.errored = true;\n\n  if (callback) {\n    return callback(error);\n  }\n\n  stream.emit(GridFSBucketWriteStream.ERROR, error);\n}\n\nfunction createChunkDoc(filesId, n, data) {\n  return {\n    _id: new bson_1.ObjectId(),\n    files_id: filesId,\n    n,\n    data\n  };\n}\n\nfunction checkChunksIndex(_x) {\n  return _checkChunksIndex.apply(this, arguments);\n}\n\nfunction _checkChunksIndex() {\n  _checkChunksIndex = _asyncToGenerator(function* (stream) {\n    const index = {\n      files_id: 1,\n      n: 1\n    };\n    let indexes;\n\n    try {\n      indexes = yield stream.chunks.listIndexes().toArray();\n    } catch (error) {\n      if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n        indexes = [];\n      } else {\n        throw error;\n      }\n    }\n\n    const hasChunksIndex = !!indexes.find(index => {\n      const keys = Object.keys(index.key);\n\n      if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n        return true;\n      }\n\n      return false;\n    });\n\n    if (!hasChunksIndex) {\n      const writeConcernOptions = getWriteOptions(stream);\n      yield stream.chunks.createIndex(index, { ...writeConcernOptions,\n        background: true,\n        unique: true\n      });\n    }\n  });\n  return _checkChunksIndex.apply(this, arguments);\n}\n\nfunction checkDone(stream, callback) {\n  if (stream.done) return true;\n\n  if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n    // Set done so we do not trigger duplicate createFilesDoc\n    stream.done = true; // Create a new files doc\n\n    const filesDoc = createFilesDoc(stream.id, stream.length, stream.chunkSizeBytes, stream.filename, stream.options.contentType, stream.options.aliases, stream.options.metadata);\n\n    if (checkAborted(stream, callback)) {\n      return false;\n    }\n\n    stream.files.insertOne(filesDoc, getWriteOptions(stream)).then(() => {\n      stream.emit(GridFSBucketWriteStream.FINISH, filesDoc);\n      stream.emit(GridFSBucketWriteStream.CLOSE);\n    }, error => {\n      return __handleError(stream, error, callback);\n    });\n    return true;\n  }\n\n  return false;\n}\n\nfunction checkIndexes(_x2) {\n  return _checkIndexes.apply(this, arguments);\n}\n\nfunction _checkIndexes() {\n  _checkIndexes = _asyncToGenerator(function* (stream) {\n    const doc = yield stream.files.findOne({}, {\n      projection: {\n        _id: 1\n      }\n    });\n\n    if (doc != null) {\n      // If at least one document exists assume the collection has the required index\n      return;\n    }\n\n    const index = {\n      filename: 1,\n      uploadDate: 1\n    };\n    let indexes;\n\n    try {\n      indexes = yield stream.files.listIndexes().toArray();\n    } catch (error) {\n      if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n        indexes = [];\n      } else {\n        throw error;\n      }\n    }\n\n    const hasFileIndex = !!indexes.find(index => {\n      const keys = Object.keys(index.key);\n\n      if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n        return true;\n      }\n\n      return false;\n    });\n\n    if (!hasFileIndex) {\n      yield stream.files.createIndex(index, {\n        background: false\n      });\n    }\n\n    yield checkChunksIndex(stream);\n  });\n  return _checkIndexes.apply(this, arguments);\n}\n\nfunction createFilesDoc(_id, length, chunkSize, filename, contentType, aliases, metadata) {\n  const ret = {\n    _id,\n    length,\n    chunkSize,\n    uploadDate: new Date(),\n    filename\n  };\n\n  if (contentType) {\n    ret.contentType = contentType;\n  }\n\n  if (aliases) {\n    ret.aliases = aliases;\n  }\n\n  if (metadata) {\n    ret.metadata = metadata;\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, chunk, encoding, callback) {\n  if (checkAborted(stream, callback)) {\n    return false;\n  }\n\n  const inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n  stream.length += inputBuf.length; // Input is small enough to fit in our buffer\n\n  if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n    inputBuf.copy(stream.bufToStore, stream.pos);\n    stream.pos += inputBuf.length;\n    callback && callback(); // Note that we reverse the typical semantics of write's return value\n    // to be compatible with node's `.pipe()` function.\n    // True means client can keep writing.\n\n    return true;\n  } // Otherwise, buffer is too big for current chunk, so we need to flush\n  // to MongoDB.\n\n\n  let inputBufRemaining = inputBuf.length;\n  let spaceRemaining = stream.chunkSizeBytes - stream.pos;\n  let numToCopy = Math.min(spaceRemaining, inputBuf.length);\n  let outstandingRequests = 0;\n\n  while (inputBufRemaining > 0) {\n    const inputBufPos = inputBuf.length - inputBufRemaining;\n    inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n    stream.pos += numToCopy;\n    spaceRemaining -= numToCopy;\n    let doc;\n\n    if (spaceRemaining === 0) {\n      doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n      ++stream.state.outstandingRequests;\n      ++outstandingRequests;\n\n      if (checkAborted(stream, callback)) {\n        return false;\n      }\n\n      stream.chunks.insertOne(doc, getWriteOptions(stream)).then(() => {\n        --stream.state.outstandingRequests;\n        --outstandingRequests;\n\n        if (!outstandingRequests) {\n          stream.emit('drain', doc);\n          callback && callback();\n          checkDone(stream);\n        }\n      }, error => {\n        return __handleError(stream, error);\n      });\n      spaceRemaining = stream.chunkSizeBytes;\n      stream.pos = 0;\n      ++stream.n;\n    }\n\n    inputBufRemaining -= numToCopy;\n    numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n  } // Note that we reverse the typical semantics of write's return value\n  // to be compatible with node's `.pipe()` function.\n  // False means the client should wait for the 'drain' event.\n\n\n  return false;\n}\n\nfunction getWriteOptions(stream) {\n  const obj = {};\n\n  if (stream.writeConcern) {\n    obj.writeConcern = {\n      w: stream.writeConcern.w,\n      wtimeout: stream.writeConcern.wtimeout,\n      j: stream.writeConcern.j\n    };\n  }\n\n  return obj;\n}\n\nfunction waitForIndexes(stream, callback) {\n  if (stream.bucket.s.checkedIndexes) {\n    return callback(false);\n  }\n\n  stream.bucket.once('index', () => {\n    callback(true);\n  });\n  return true;\n}\n\nfunction writeRemnant(stream, callback) {\n  // Buffer is empty, so don't bother to insert\n  if (stream.pos === 0) {\n    return checkDone(stream, callback);\n  }\n\n  ++stream.state.outstandingRequests; // Create a new buffer to make sure the buffer isn't bigger than it needs\n  // to be.\n\n  const remnant = Buffer.alloc(stream.pos);\n  stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n  const doc = createChunkDoc(stream.id, stream.n, remnant); // If the stream was aborted, do not write remnant\n\n  if (checkAborted(stream, callback)) {\n    return false;\n  }\n\n  stream.chunks.insertOne(doc, getWriteOptions(stream)).then(() => {\n    --stream.state.outstandingRequests;\n    checkDone(stream);\n  }, error => {\n    return __handleError(stream, error);\n  });\n  return true;\n}\n\nfunction checkAborted(stream, callback) {\n  if (stream.state.aborted) {\n    if (typeof callback === 'function') {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosedError\n      callback(new error_1.MongoAPIError('Stream has been aborted'));\n    }\n\n    return true;\n  }\n\n  return false;\n}","map":{"version":3,"sources":["D:/dev-projects/APEX/Legalalliance/node_modules/mongodb/lib/gridfs/upload.js"],"names":["Object","defineProperty","exports","value","GridFSBucketWriteStream","stream_1","require","bson_1","error_1","write_concern_1","Writable","constructor","bucket","filename","options","chunks","s","_chunksCollection","files","_filesCollection","writeConcern","WriteConcern","fromOptions","done","id","ObjectId","chunkSizeBytes","bufToStore","Buffer","alloc","length","n","pos","state","streamEnd","outstandingRequests","errored","aborted","calledOpenUploadStream","checkIndexes","then","checkedIndexes","emit","write","chunk","encodingOrCallback","callback","encoding","undefined","waitForIndexes","doWrite","abort","MongoAPIError","deleteMany","files_id","end","chunkOrCallback","checkAborted","once","FINISH","result","writeRemnant","CLOSE","ERROR","__handleError","stream","error","createChunkDoc","filesId","data","_id","checkChunksIndex","index","indexes","listIndexes","toArray","MongoError","code","MONGODB_ERROR_CODES","NamespaceNotFound","hasChunksIndex","find","keys","key","writeConcernOptions","getWriteOptions","createIndex","background","unique","checkDone","filesDoc","createFilesDoc","contentType","aliases","metadata","insertOne","doc","findOne","projection","uploadDate","hasFileIndex","chunkSize","ret","Date","inputBuf","isBuffer","from","copy","inputBufRemaining","spaceRemaining","numToCopy","Math","min","inputBufPos","obj","w","wtimeout","j","remnant"],"mappings":"AAAA;;;;AACAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAAEC,EAAAA,KAAK,EAAE;AAAT,CAA7C;AACAD,OAAO,CAACE,uBAAR,GAAkC,KAAK,CAAvC;;AACA,MAAMC,QAAQ,GAAGC,OAAO,CAAC,QAAD,CAAxB;;AACA,MAAMC,MAAM,GAAGD,OAAO,CAAC,SAAD,CAAtB;;AACA,MAAME,OAAO,GAAGF,OAAO,CAAC,UAAD,CAAvB;;AACA,MAAMG,eAAe,GAAGH,OAAO,CAAC,oBAAD,CAA/B;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAMF,uBAAN,SAAsCC,QAAQ,CAACK,QAA/C,CAAwD;AACpD;AACJ;AACA;AACA;AACA;AACA;AACIC,EAAAA,WAAW,CAACC,MAAD,EAASC,QAAT,EAAmBC,OAAnB,EAA4B;AACnC;AACAA,IAAAA,OAAO,GAAGA,OAAO,IAAI,EAArB;AACA,SAAKF,MAAL,GAAcA,MAAd;AACA,SAAKG,MAAL,GAAcH,MAAM,CAACI,CAAP,CAASC,iBAAvB;AACA,SAAKJ,QAAL,GAAgBA,QAAhB;AACA,SAAKK,KAAL,GAAaN,MAAM,CAACI,CAAP,CAASG,gBAAtB;AACA,SAAKL,OAAL,GAAeA,OAAf;AACA,SAAKM,YAAL,GAAoBX,eAAe,CAACY,YAAhB,CAA6BC,WAA7B,CAAyCR,OAAzC,KAAqDF,MAAM,CAACI,CAAP,CAASF,OAAT,CAAiBM,YAA1F,CARmC,CASnC;;AACA,SAAKG,IAAL,GAAY,KAAZ;AACA,SAAKC,EAAL,GAAUV,OAAO,CAACU,EAAR,GAAaV,OAAO,CAACU,EAArB,GAA0B,IAAIjB,MAAM,CAACkB,QAAX,EAApC,CAXmC,CAYnC;;AACA,SAAKC,cAAL,GAAsBZ,OAAO,CAACY,cAAR,IAA0B,KAAKd,MAAL,CAAYI,CAAZ,CAAcF,OAAd,CAAsBY,cAAtE;AACA,SAAKC,UAAL,GAAkBC,MAAM,CAACC,KAAP,CAAa,KAAKH,cAAlB,CAAlB;AACA,SAAKI,MAAL,GAAc,CAAd;AACA,SAAKC,CAAL,GAAS,CAAT;AACA,SAAKC,GAAL,GAAW,CAAX;AACA,SAAKC,KAAL,GAAa;AACTC,MAAAA,SAAS,EAAE,KADF;AAETC,MAAAA,mBAAmB,EAAE,CAFZ;AAGTC,MAAAA,OAAO,EAAE,KAHA;AAITC,MAAAA,OAAO,EAAE;AAJA,KAAb;;AAMA,QAAI,CAAC,KAAKzB,MAAL,CAAYI,CAAZ,CAAcsB,sBAAnB,EAA2C;AACvC,WAAK1B,MAAL,CAAYI,CAAZ,CAAcsB,sBAAd,GAAuC,IAAvC;AACAC,MAAAA,YAAY,CAAC,IAAD,CAAZ,CAAmBC,IAAnB,CAAwB,MAAM;AAC1B,aAAK5B,MAAL,CAAYI,CAAZ,CAAcyB,cAAd,GAA+B,IAA/B;AACA,aAAK7B,MAAL,CAAY8B,IAAZ,CAAiB,OAAjB;AACH,OAHD,EAGG,MAAM,IAHT;AAIH;AACJ;;AACDC,EAAAA,KAAK,CAACC,KAAD,EAAQC,kBAAR,EAA4BC,QAA5B,EAAsC;AACvC,UAAMC,QAAQ,GAAG,OAAOF,kBAAP,KAA8B,UAA9B,GAA2CG,SAA3C,GAAuDH,kBAAxE;AACAC,IAAAA,QAAQ,GAAG,OAAOD,kBAAP,KAA8B,UAA9B,GAA2CA,kBAA3C,GAAgEC,QAA3E;AACA,WAAOG,cAAc,CAAC,IAAD,EAAO,MAAMC,OAAO,CAAC,IAAD,EAAON,KAAP,EAAcG,QAAd,EAAwBD,QAAxB,CAApB,CAArB;AACH;AACD;AACJ;AACA;AACA;;;AACUK,EAAAA,KAAK,GAAG;AAAA;;AAAA;AACV,UAAI,KAAI,CAAClB,KAAL,CAAWC,SAAf,EAA0B;AACtB;AACA,cAAM,IAAI1B,OAAO,CAAC4C,aAAZ,CAA0B,kDAA1B,CAAN;AACH;;AACD,UAAI,KAAI,CAACnB,KAAL,CAAWI,OAAf,EAAwB;AACpB;AACA,cAAM,IAAI7B,OAAO,CAAC4C,aAAZ,CAA0B,uCAA1B,CAAN;AACH;;AACD,MAAA,KAAI,CAACnB,KAAL,CAAWI,OAAX,GAAqB,IAArB;AACA,YAAM,KAAI,CAACtB,MAAL,CAAYsC,UAAZ,CAAuB;AAAEC,QAAAA,QAAQ,EAAE,KAAI,CAAC9B;AAAjB,OAAvB,CAAN;AAVU;AAWb;;AACD+B,EAAAA,GAAG,CAACC,eAAD,EAAkBX,kBAAlB,EAAsCC,QAAtC,EAAgD;AAC/C,UAAMF,KAAK,GAAG,OAAOY,eAAP,KAA2B,UAA3B,GAAwCR,SAAxC,GAAoDQ,eAAlE;AACA,UAAMT,QAAQ,GAAG,OAAOF,kBAAP,KAA8B,UAA9B,GAA2CG,SAA3C,GAAuDH,kBAAxE;AACAC,IAAAA,QAAQ,GACJ,OAAOU,eAAP,KAA2B,UAA3B,GACMA,eADN,GAEM,OAAOX,kBAAP,KAA8B,UAA9B,GACIA,kBADJ,GAEIC,QALd;AAMA,QAAI,KAAKb,KAAL,CAAWC,SAAX,IAAwBuB,YAAY,CAAC,IAAD,EAAOX,QAAP,CAAxC,EACI,OAAO,IAAP;AACJ,SAAKb,KAAL,CAAWC,SAAX,GAAuB,IAAvB;;AACA,QAAIY,QAAJ,EAAc;AACV,WAAKY,IAAL,CAAUtD,uBAAuB,CAACuD,MAAlC,EAA2CC,MAAD,IAAY;AAClD,YAAId,QAAJ,EACIA,QAAQ,CAACE,SAAD,EAAYY,MAAZ,CAAR;AACP,OAHD;AAIH;;AACD,QAAI,CAAChB,KAAL,EAAY;AACRK,MAAAA,cAAc,CAAC,IAAD,EAAO,MAAM,CAAC,CAACY,YAAY,CAAC,IAAD,CAA3B,CAAd;AACA,aAAO,IAAP;AACH;;AACD,SAAKlB,KAAL,CAAWC,KAAX,EAAkBG,QAAlB,EAA4B,MAAM;AAC9Bc,MAAAA,YAAY,CAAC,IAAD,CAAZ;AACH,KAFD;AAGA,WAAO,IAAP;AACH;;AAtFmD;;AAwFxD3D,OAAO,CAACE,uBAAR,GAAkCA,uBAAlC;AACA;;AACAA,uBAAuB,CAAC0D,KAAxB,GAAgC,OAAhC;AACA;;AACA1D,uBAAuB,CAAC2D,KAAxB,GAAgC,OAAhC;AACA;AACA;AACA;AACA;;AACA3D,uBAAuB,CAACuD,MAAxB,GAAiC,QAAjC;;AACA,SAASK,aAAT,CAAuBC,MAAvB,EAA+BC,KAA/B,EAAsCpB,QAAtC,EAAgD;AAC5C,MAAImB,MAAM,CAAChC,KAAP,CAAaG,OAAjB,EAA0B;AACtB;AACH;;AACD6B,EAAAA,MAAM,CAAChC,KAAP,CAAaG,OAAb,GAAuB,IAAvB;;AACA,MAAIU,QAAJ,EAAc;AACV,WAAOA,QAAQ,CAACoB,KAAD,CAAf;AACH;;AACDD,EAAAA,MAAM,CAACvB,IAAP,CAAYtC,uBAAuB,CAAC2D,KAApC,EAA2CG,KAA3C;AACH;;AACD,SAASC,cAAT,CAAwBC,OAAxB,EAAiCrC,CAAjC,EAAoCsC,IAApC,EAA0C;AACtC,SAAO;AACHC,IAAAA,GAAG,EAAE,IAAI/D,MAAM,CAACkB,QAAX,EADF;AAEH6B,IAAAA,QAAQ,EAAEc,OAFP;AAGHrC,IAAAA,CAHG;AAIHsC,IAAAA;AAJG,GAAP;AAMH;;SACcE,gB;;;;;wCAAf,WAAgCN,MAAhC,EAAwC;AACpC,UAAMO,KAAK,GAAG;AAAElB,MAAAA,QAAQ,EAAE,CAAZ;AAAevB,MAAAA,CAAC,EAAE;AAAlB,KAAd;AACA,QAAI0C,OAAJ;;AACA,QAAI;AACAA,MAAAA,OAAO,SAASR,MAAM,CAAClD,MAAP,CAAc2D,WAAd,GAA4BC,OAA5B,EAAhB;AACH,KAFD,CAGA,OAAOT,KAAP,EAAc;AACV,UAAIA,KAAK,YAAY1D,OAAO,CAACoE,UAAzB,IAAuCV,KAAK,CAACW,IAAN,KAAerE,OAAO,CAACsE,mBAAR,CAA4BC,iBAAtF,EAAyG;AACrGN,QAAAA,OAAO,GAAG,EAAV;AACH,OAFD,MAGK;AACD,cAAMP,KAAN;AACH;AACJ;;AACD,UAAMc,cAAc,GAAG,CAAC,CAACP,OAAO,CAACQ,IAAR,CAAaT,KAAK,IAAI;AAC3C,YAAMU,IAAI,GAAGlF,MAAM,CAACkF,IAAP,CAAYV,KAAK,CAACW,GAAlB,CAAb;;AACA,UAAID,IAAI,CAACpD,MAAL,KAAgB,CAAhB,IAAqB0C,KAAK,CAACW,GAAN,CAAU7B,QAAV,KAAuB,CAA5C,IAAiDkB,KAAK,CAACW,GAAN,CAAUpD,CAAV,KAAgB,CAArE,EAAwE;AACpE,eAAO,IAAP;AACH;;AACD,aAAO,KAAP;AACH,KANwB,CAAzB;;AAOA,QAAI,CAACiD,cAAL,EAAqB;AACjB,YAAMI,mBAAmB,GAAGC,eAAe,CAACpB,MAAD,CAA3C;AACA,YAAMA,MAAM,CAAClD,MAAP,CAAcuE,WAAd,CAA0Bd,KAA1B,EAAiC,EACnC,GAAGY,mBADgC;AAEnCG,QAAAA,UAAU,EAAE,IAFuB;AAGnCC,QAAAA,MAAM,EAAE;AAH2B,OAAjC,CAAN;AAKH;AACJ,G;;;;AACD,SAASC,SAAT,CAAmBxB,MAAnB,EAA2BnB,QAA3B,EAAqC;AACjC,MAAImB,MAAM,CAAC1C,IAAX,EACI,OAAO,IAAP;;AACJ,MAAI0C,MAAM,CAAChC,KAAP,CAAaC,SAAb,IAA0B+B,MAAM,CAAChC,KAAP,CAAaE,mBAAb,KAAqC,CAA/D,IAAoE,CAAC8B,MAAM,CAAChC,KAAP,CAAaG,OAAtF,EAA+F;AAC3F;AACA6B,IAAAA,MAAM,CAAC1C,IAAP,GAAc,IAAd,CAF2F,CAG3F;;AACA,UAAMmE,QAAQ,GAAGC,cAAc,CAAC1B,MAAM,CAACzC,EAAR,EAAYyC,MAAM,CAACnC,MAAnB,EAA2BmC,MAAM,CAACvC,cAAlC,EAAkDuC,MAAM,CAACpD,QAAzD,EAAmEoD,MAAM,CAACnD,OAAP,CAAe8E,WAAlF,EAA+F3B,MAAM,CAACnD,OAAP,CAAe+E,OAA9G,EAAuH5B,MAAM,CAACnD,OAAP,CAAegF,QAAtI,CAA/B;;AACA,QAAIrC,YAAY,CAACQ,MAAD,EAASnB,QAAT,CAAhB,EAAoC;AAChC,aAAO,KAAP;AACH;;AACDmB,IAAAA,MAAM,CAAC/C,KAAP,CAAa6E,SAAb,CAAuBL,QAAvB,EAAiCL,eAAe,CAACpB,MAAD,CAAhD,EAA0DzB,IAA1D,CAA+D,MAAM;AACjEyB,MAAAA,MAAM,CAACvB,IAAP,CAAYtC,uBAAuB,CAACuD,MAApC,EAA4C+B,QAA5C;AACAzB,MAAAA,MAAM,CAACvB,IAAP,CAAYtC,uBAAuB,CAAC0D,KAApC;AACH,KAHD,EAGGI,KAAK,IAAI;AACR,aAAOF,aAAa,CAACC,MAAD,EAASC,KAAT,EAAgBpB,QAAhB,CAApB;AACH,KALD;AAMA,WAAO,IAAP;AACH;;AACD,SAAO,KAAP;AACH;;SACcP,Y;;;;;oCAAf,WAA4B0B,MAA5B,EAAoC;AAChC,UAAM+B,GAAG,SAAS/B,MAAM,CAAC/C,KAAP,CAAa+E,OAAb,CAAqB,EAArB,EAAyB;AAAEC,MAAAA,UAAU,EAAE;AAAE5B,QAAAA,GAAG,EAAE;AAAP;AAAd,KAAzB,CAAlB;;AACA,QAAI0B,GAAG,IAAI,IAAX,EAAiB;AACb;AACA;AACH;;AACD,UAAMxB,KAAK,GAAG;AAAE3D,MAAAA,QAAQ,EAAE,CAAZ;AAAesF,MAAAA,UAAU,EAAE;AAA3B,KAAd;AACA,QAAI1B,OAAJ;;AACA,QAAI;AACAA,MAAAA,OAAO,SAASR,MAAM,CAAC/C,KAAP,CAAawD,WAAb,GAA2BC,OAA3B,EAAhB;AACH,KAFD,CAGA,OAAOT,KAAP,EAAc;AACV,UAAIA,KAAK,YAAY1D,OAAO,CAACoE,UAAzB,IAAuCV,KAAK,CAACW,IAAN,KAAerE,OAAO,CAACsE,mBAAR,CAA4BC,iBAAtF,EAAyG;AACrGN,QAAAA,OAAO,GAAG,EAAV;AACH,OAFD,MAGK;AACD,cAAMP,KAAN;AACH;AACJ;;AACD,UAAMkC,YAAY,GAAG,CAAC,CAAC3B,OAAO,CAACQ,IAAR,CAAaT,KAAK,IAAI;AACzC,YAAMU,IAAI,GAAGlF,MAAM,CAACkF,IAAP,CAAYV,KAAK,CAACW,GAAlB,CAAb;;AACA,UAAID,IAAI,CAACpD,MAAL,KAAgB,CAAhB,IAAqB0C,KAAK,CAACW,GAAN,CAAUtE,QAAV,KAAuB,CAA5C,IAAiD2D,KAAK,CAACW,GAAN,CAAUgB,UAAV,KAAyB,CAA9E,EAAiF;AAC7E,eAAO,IAAP;AACH;;AACD,aAAO,KAAP;AACH,KANsB,CAAvB;;AAOA,QAAI,CAACC,YAAL,EAAmB;AACf,YAAMnC,MAAM,CAAC/C,KAAP,CAAaoE,WAAb,CAAyBd,KAAzB,EAAgC;AAAEe,QAAAA,UAAU,EAAE;AAAd,OAAhC,CAAN;AACH;;AACD,UAAMhB,gBAAgB,CAACN,MAAD,CAAtB;AACH,G;;;;AACD,SAAS0B,cAAT,CAAwBrB,GAAxB,EAA6BxC,MAA7B,EAAqCuE,SAArC,EAAgDxF,QAAhD,EAA0D+E,WAA1D,EAAuEC,OAAvE,EAAgFC,QAAhF,EAA0F;AACtF,QAAMQ,GAAG,GAAG;AACRhC,IAAAA,GADQ;AAERxC,IAAAA,MAFQ;AAGRuE,IAAAA,SAHQ;AAIRF,IAAAA,UAAU,EAAE,IAAII,IAAJ,EAJJ;AAKR1F,IAAAA;AALQ,GAAZ;;AAOA,MAAI+E,WAAJ,EAAiB;AACbU,IAAAA,GAAG,CAACV,WAAJ,GAAkBA,WAAlB;AACH;;AACD,MAAIC,OAAJ,EAAa;AACTS,IAAAA,GAAG,CAACT,OAAJ,GAAcA,OAAd;AACH;;AACD,MAAIC,QAAJ,EAAc;AACVQ,IAAAA,GAAG,CAACR,QAAJ,GAAeA,QAAf;AACH;;AACD,SAAOQ,GAAP;AACH;;AACD,SAASpD,OAAT,CAAiBe,MAAjB,EAAyBrB,KAAzB,EAAgCG,QAAhC,EAA0CD,QAA1C,EAAoD;AAChD,MAAIW,YAAY,CAACQ,MAAD,EAASnB,QAAT,CAAhB,EAAoC;AAChC,WAAO,KAAP;AACH;;AACD,QAAM0D,QAAQ,GAAG5E,MAAM,CAAC6E,QAAP,CAAgB7D,KAAhB,IAAyBA,KAAzB,GAAiChB,MAAM,CAAC8E,IAAP,CAAY9D,KAAZ,EAAmBG,QAAnB,CAAlD;AACAkB,EAAAA,MAAM,CAACnC,MAAP,IAAiB0E,QAAQ,CAAC1E,MAA1B,CALgD,CAMhD;;AACA,MAAImC,MAAM,CAACjC,GAAP,GAAawE,QAAQ,CAAC1E,MAAtB,GAA+BmC,MAAM,CAACvC,cAA1C,EAA0D;AACtD8E,IAAAA,QAAQ,CAACG,IAAT,CAAc1C,MAAM,CAACtC,UAArB,EAAiCsC,MAAM,CAACjC,GAAxC;AACAiC,IAAAA,MAAM,CAACjC,GAAP,IAAcwE,QAAQ,CAAC1E,MAAvB;AACAgB,IAAAA,QAAQ,IAAIA,QAAQ,EAApB,CAHsD,CAItD;AACA;AACA;;AACA,WAAO,IAAP;AACH,GAf+C,CAgBhD;AACA;;;AACA,MAAI8D,iBAAiB,GAAGJ,QAAQ,CAAC1E,MAAjC;AACA,MAAI+E,cAAc,GAAG5C,MAAM,CAACvC,cAAP,GAAwBuC,MAAM,CAACjC,GAApD;AACA,MAAI8E,SAAS,GAAGC,IAAI,CAACC,GAAL,CAASH,cAAT,EAAyBL,QAAQ,CAAC1E,MAAlC,CAAhB;AACA,MAAIK,mBAAmB,GAAG,CAA1B;;AACA,SAAOyE,iBAAiB,GAAG,CAA3B,EAA8B;AAC1B,UAAMK,WAAW,GAAGT,QAAQ,CAAC1E,MAAT,GAAkB8E,iBAAtC;AACAJ,IAAAA,QAAQ,CAACG,IAAT,CAAc1C,MAAM,CAACtC,UAArB,EAAiCsC,MAAM,CAACjC,GAAxC,EAA6CiF,WAA7C,EAA0DA,WAAW,GAAGH,SAAxE;AACA7C,IAAAA,MAAM,CAACjC,GAAP,IAAc8E,SAAd;AACAD,IAAAA,cAAc,IAAIC,SAAlB;AACA,QAAId,GAAJ;;AACA,QAAIa,cAAc,KAAK,CAAvB,EAA0B;AACtBb,MAAAA,GAAG,GAAG7B,cAAc,CAACF,MAAM,CAACzC,EAAR,EAAYyC,MAAM,CAAClC,CAAnB,EAAsBH,MAAM,CAAC8E,IAAP,CAAYzC,MAAM,CAACtC,UAAnB,CAAtB,CAApB;AACA,QAAEsC,MAAM,CAAChC,KAAP,CAAaE,mBAAf;AACA,QAAEA,mBAAF;;AACA,UAAIsB,YAAY,CAACQ,MAAD,EAASnB,QAAT,CAAhB,EAAoC;AAChC,eAAO,KAAP;AACH;;AACDmB,MAAAA,MAAM,CAAClD,MAAP,CAAcgF,SAAd,CAAwBC,GAAxB,EAA6BX,eAAe,CAACpB,MAAD,CAA5C,EAAsDzB,IAAtD,CAA2D,MAAM;AAC7D,UAAEyB,MAAM,CAAChC,KAAP,CAAaE,mBAAf;AACA,UAAEA,mBAAF;;AACA,YAAI,CAACA,mBAAL,EAA0B;AACtB8B,UAAAA,MAAM,CAACvB,IAAP,CAAY,OAAZ,EAAqBsD,GAArB;AACAlD,UAAAA,QAAQ,IAAIA,QAAQ,EAApB;AACA2C,UAAAA,SAAS,CAACxB,MAAD,CAAT;AACH;AACJ,OARD,EAQGC,KAAK,IAAI;AACR,eAAOF,aAAa,CAACC,MAAD,EAASC,KAAT,CAApB;AACH,OAVD;AAWA2C,MAAAA,cAAc,GAAG5C,MAAM,CAACvC,cAAxB;AACAuC,MAAAA,MAAM,CAACjC,GAAP,GAAa,CAAb;AACA,QAAEiC,MAAM,CAAClC,CAAT;AACH;;AACD6E,IAAAA,iBAAiB,IAAIE,SAArB;AACAA,IAAAA,SAAS,GAAGC,IAAI,CAACC,GAAL,CAASH,cAAT,EAAyBD,iBAAzB,CAAZ;AACH,GApD+C,CAqDhD;AACA;AACA;;;AACA,SAAO,KAAP;AACH;;AACD,SAASvB,eAAT,CAAyBpB,MAAzB,EAAiC;AAC7B,QAAMiD,GAAG,GAAG,EAAZ;;AACA,MAAIjD,MAAM,CAAC7C,YAAX,EAAyB;AACrB8F,IAAAA,GAAG,CAAC9F,YAAJ,GAAmB;AACf+F,MAAAA,CAAC,EAAElD,MAAM,CAAC7C,YAAP,CAAoB+F,CADR;AAEfC,MAAAA,QAAQ,EAAEnD,MAAM,CAAC7C,YAAP,CAAoBgG,QAFf;AAGfC,MAAAA,CAAC,EAAEpD,MAAM,CAAC7C,YAAP,CAAoBiG;AAHR,KAAnB;AAKH;;AACD,SAAOH,GAAP;AACH;;AACD,SAASjE,cAAT,CAAwBgB,MAAxB,EAAgCnB,QAAhC,EAA0C;AACtC,MAAImB,MAAM,CAACrD,MAAP,CAAcI,CAAd,CAAgByB,cAApB,EAAoC;AAChC,WAAOK,QAAQ,CAAC,KAAD,CAAf;AACH;;AACDmB,EAAAA,MAAM,CAACrD,MAAP,CAAc8C,IAAd,CAAmB,OAAnB,EAA4B,MAAM;AAC9BZ,IAAAA,QAAQ,CAAC,IAAD,CAAR;AACH,GAFD;AAGA,SAAO,IAAP;AACH;;AACD,SAASe,YAAT,CAAsBI,MAAtB,EAA8BnB,QAA9B,EAAwC;AACpC;AACA,MAAImB,MAAM,CAACjC,GAAP,KAAe,CAAnB,EAAsB;AAClB,WAAOyD,SAAS,CAACxB,MAAD,EAASnB,QAAT,CAAhB;AACH;;AACD,IAAEmB,MAAM,CAAChC,KAAP,CAAaE,mBAAf,CALoC,CAMpC;AACA;;AACA,QAAMmF,OAAO,GAAG1F,MAAM,CAACC,KAAP,CAAaoC,MAAM,CAACjC,GAApB,CAAhB;AACAiC,EAAAA,MAAM,CAACtC,UAAP,CAAkBgF,IAAlB,CAAuBW,OAAvB,EAAgC,CAAhC,EAAmC,CAAnC,EAAsCrD,MAAM,CAACjC,GAA7C;AACA,QAAMgE,GAAG,GAAG7B,cAAc,CAACF,MAAM,CAACzC,EAAR,EAAYyC,MAAM,CAAClC,CAAnB,EAAsBuF,OAAtB,CAA1B,CAVoC,CAWpC;;AACA,MAAI7D,YAAY,CAACQ,MAAD,EAASnB,QAAT,CAAhB,EAAoC;AAChC,WAAO,KAAP;AACH;;AACDmB,EAAAA,MAAM,CAAClD,MAAP,CAAcgF,SAAd,CAAwBC,GAAxB,EAA6BX,eAAe,CAACpB,MAAD,CAA5C,EAAsDzB,IAAtD,CAA2D,MAAM;AAC7D,MAAEyB,MAAM,CAAChC,KAAP,CAAaE,mBAAf;AACAsD,IAAAA,SAAS,CAACxB,MAAD,CAAT;AACH,GAHD,EAGGC,KAAK,IAAI;AACR,WAAOF,aAAa,CAACC,MAAD,EAASC,KAAT,CAApB;AACH,GALD;AAMA,SAAO,IAAP;AACH;;AACD,SAAST,YAAT,CAAsBQ,MAAtB,EAA8BnB,QAA9B,EAAwC;AACpC,MAAImB,MAAM,CAAChC,KAAP,CAAaI,OAAjB,EAA0B;AACtB,QAAI,OAAOS,QAAP,KAAoB,UAAxB,EAAoC;AAChC;AACAA,MAAAA,QAAQ,CAAC,IAAItC,OAAO,CAAC4C,aAAZ,CAA0B,yBAA1B,CAAD,CAAR;AACH;;AACD,WAAO,IAAP;AACH;;AACD,SAAO,KAAP;AACH","sourcesContent":["\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.GridFSBucketWriteStream = void 0;\nconst stream_1 = require(\"stream\");\nconst bson_1 = require(\"../bson\");\nconst error_1 = require(\"../error\");\nconst write_concern_1 = require(\"./../write_concern\");\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n * @public\n */\nclass GridFSBucketWriteStream extends stream_1.Writable {\n    /**\n     * @param bucket - Handle for this stream's corresponding bucket\n     * @param filename - The value of the 'filename' key in the files doc\n     * @param options - Optional settings.\n     * @internal\n     */\n    constructor(bucket, filename, options) {\n        super();\n        options = options ?? {};\n        this.bucket = bucket;\n        this.chunks = bucket.s._chunksCollection;\n        this.filename = filename;\n        this.files = bucket.s._filesCollection;\n        this.options = options;\n        this.writeConcern = write_concern_1.WriteConcern.fromOptions(options) || bucket.s.options.writeConcern;\n        // Signals the write is all done\n        this.done = false;\n        this.id = options.id ? options.id : new bson_1.ObjectId();\n        // properly inherit the default chunksize from parent\n        this.chunkSizeBytes = options.chunkSizeBytes || this.bucket.s.options.chunkSizeBytes;\n        this.bufToStore = Buffer.alloc(this.chunkSizeBytes);\n        this.length = 0;\n        this.n = 0;\n        this.pos = 0;\n        this.state = {\n            streamEnd: false,\n            outstandingRequests: 0,\n            errored: false,\n            aborted: false\n        };\n        if (!this.bucket.s.calledOpenUploadStream) {\n            this.bucket.s.calledOpenUploadStream = true;\n            checkIndexes(this).then(() => {\n                this.bucket.s.checkedIndexes = true;\n                this.bucket.emit('index');\n            }, () => null);\n        }\n    }\n    write(chunk, encodingOrCallback, callback) {\n        const encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\n        callback = typeof encodingOrCallback === 'function' ? encodingOrCallback : callback;\n        return waitForIndexes(this, () => doWrite(this, chunk, encoding, callback));\n    }\n    /**\n     * Places this write stream into an aborted state (all future writes fail)\n     * and deletes all chunks that have already been written.\n     */\n    async abort() {\n        if (this.state.streamEnd) {\n            // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n            throw new error_1.MongoAPIError('Cannot abort a stream that has already completed');\n        }\n        if (this.state.aborted) {\n            // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n            throw new error_1.MongoAPIError('Cannot call abort() on a stream twice');\n        }\n        this.state.aborted = true;\n        await this.chunks.deleteMany({ files_id: this.id });\n    }\n    end(chunkOrCallback, encodingOrCallback, callback) {\n        const chunk = typeof chunkOrCallback === 'function' ? undefined : chunkOrCallback;\n        const encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\n        callback =\n            typeof chunkOrCallback === 'function'\n                ? chunkOrCallback\n                : typeof encodingOrCallback === 'function'\n                    ? encodingOrCallback\n                    : callback;\n        if (this.state.streamEnd || checkAborted(this, callback))\n            return this;\n        this.state.streamEnd = true;\n        if (callback) {\n            this.once(GridFSBucketWriteStream.FINISH, (result) => {\n                if (callback)\n                    callback(undefined, result);\n            });\n        }\n        if (!chunk) {\n            waitForIndexes(this, () => !!writeRemnant(this));\n            return this;\n        }\n        this.write(chunk, encoding, () => {\n            writeRemnant(this);\n        });\n        return this;\n    }\n}\nexports.GridFSBucketWriteStream = GridFSBucketWriteStream;\n/** @event */\nGridFSBucketWriteStream.CLOSE = 'close';\n/** @event */\nGridFSBucketWriteStream.ERROR = 'error';\n/**\n * `end()` was called and the write stream successfully wrote the file metadata and all the chunks to MongoDB.\n * @event\n */\nGridFSBucketWriteStream.FINISH = 'finish';\nfunction __handleError(stream, error, callback) {\n    if (stream.state.errored) {\n        return;\n    }\n    stream.state.errored = true;\n    if (callback) {\n        return callback(error);\n    }\n    stream.emit(GridFSBucketWriteStream.ERROR, error);\n}\nfunction createChunkDoc(filesId, n, data) {\n    return {\n        _id: new bson_1.ObjectId(),\n        files_id: filesId,\n        n,\n        data\n    };\n}\nasync function checkChunksIndex(stream) {\n    const index = { files_id: 1, n: 1 };\n    let indexes;\n    try {\n        indexes = await stream.chunks.listIndexes().toArray();\n    }\n    catch (error) {\n        if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n            indexes = [];\n        }\n        else {\n            throw error;\n        }\n    }\n    const hasChunksIndex = !!indexes.find(index => {\n        const keys = Object.keys(index.key);\n        if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n            return true;\n        }\n        return false;\n    });\n    if (!hasChunksIndex) {\n        const writeConcernOptions = getWriteOptions(stream);\n        await stream.chunks.createIndex(index, {\n            ...writeConcernOptions,\n            background: true,\n            unique: true\n        });\n    }\n}\nfunction checkDone(stream, callback) {\n    if (stream.done)\n        return true;\n    if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n        // Set done so we do not trigger duplicate createFilesDoc\n        stream.done = true;\n        // Create a new files doc\n        const filesDoc = createFilesDoc(stream.id, stream.length, stream.chunkSizeBytes, stream.filename, stream.options.contentType, stream.options.aliases, stream.options.metadata);\n        if (checkAborted(stream, callback)) {\n            return false;\n        }\n        stream.files.insertOne(filesDoc, getWriteOptions(stream)).then(() => {\n            stream.emit(GridFSBucketWriteStream.FINISH, filesDoc);\n            stream.emit(GridFSBucketWriteStream.CLOSE);\n        }, error => {\n            return __handleError(stream, error, callback);\n        });\n        return true;\n    }\n    return false;\n}\nasync function checkIndexes(stream) {\n    const doc = await stream.files.findOne({}, { projection: { _id: 1 } });\n    if (doc != null) {\n        // If at least one document exists assume the collection has the required index\n        return;\n    }\n    const index = { filename: 1, uploadDate: 1 };\n    let indexes;\n    try {\n        indexes = await stream.files.listIndexes().toArray();\n    }\n    catch (error) {\n        if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n            indexes = [];\n        }\n        else {\n            throw error;\n        }\n    }\n    const hasFileIndex = !!indexes.find(index => {\n        const keys = Object.keys(index.key);\n        if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n            return true;\n        }\n        return false;\n    });\n    if (!hasFileIndex) {\n        await stream.files.createIndex(index, { background: false });\n    }\n    await checkChunksIndex(stream);\n}\nfunction createFilesDoc(_id, length, chunkSize, filename, contentType, aliases, metadata) {\n    const ret = {\n        _id,\n        length,\n        chunkSize,\n        uploadDate: new Date(),\n        filename\n    };\n    if (contentType) {\n        ret.contentType = contentType;\n    }\n    if (aliases) {\n        ret.aliases = aliases;\n    }\n    if (metadata) {\n        ret.metadata = metadata;\n    }\n    return ret;\n}\nfunction doWrite(stream, chunk, encoding, callback) {\n    if (checkAborted(stream, callback)) {\n        return false;\n    }\n    const inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n    stream.length += inputBuf.length;\n    // Input is small enough to fit in our buffer\n    if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n        inputBuf.copy(stream.bufToStore, stream.pos);\n        stream.pos += inputBuf.length;\n        callback && callback();\n        // Note that we reverse the typical semantics of write's return value\n        // to be compatible with node's `.pipe()` function.\n        // True means client can keep writing.\n        return true;\n    }\n    // Otherwise, buffer is too big for current chunk, so we need to flush\n    // to MongoDB.\n    let inputBufRemaining = inputBuf.length;\n    let spaceRemaining = stream.chunkSizeBytes - stream.pos;\n    let numToCopy = Math.min(spaceRemaining, inputBuf.length);\n    let outstandingRequests = 0;\n    while (inputBufRemaining > 0) {\n        const inputBufPos = inputBuf.length - inputBufRemaining;\n        inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n        stream.pos += numToCopy;\n        spaceRemaining -= numToCopy;\n        let doc;\n        if (spaceRemaining === 0) {\n            doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n            ++stream.state.outstandingRequests;\n            ++outstandingRequests;\n            if (checkAborted(stream, callback)) {\n                return false;\n            }\n            stream.chunks.insertOne(doc, getWriteOptions(stream)).then(() => {\n                --stream.state.outstandingRequests;\n                --outstandingRequests;\n                if (!outstandingRequests) {\n                    stream.emit('drain', doc);\n                    callback && callback();\n                    checkDone(stream);\n                }\n            }, error => {\n                return __handleError(stream, error);\n            });\n            spaceRemaining = stream.chunkSizeBytes;\n            stream.pos = 0;\n            ++stream.n;\n        }\n        inputBufRemaining -= numToCopy;\n        numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n    }\n    // Note that we reverse the typical semantics of write's return value\n    // to be compatible with node's `.pipe()` function.\n    // False means the client should wait for the 'drain' event.\n    return false;\n}\nfunction getWriteOptions(stream) {\n    const obj = {};\n    if (stream.writeConcern) {\n        obj.writeConcern = {\n            w: stream.writeConcern.w,\n            wtimeout: stream.writeConcern.wtimeout,\n            j: stream.writeConcern.j\n        };\n    }\n    return obj;\n}\nfunction waitForIndexes(stream, callback) {\n    if (stream.bucket.s.checkedIndexes) {\n        return callback(false);\n    }\n    stream.bucket.once('index', () => {\n        callback(true);\n    });\n    return true;\n}\nfunction writeRemnant(stream, callback) {\n    // Buffer is empty, so don't bother to insert\n    if (stream.pos === 0) {\n        return checkDone(stream, callback);\n    }\n    ++stream.state.outstandingRequests;\n    // Create a new buffer to make sure the buffer isn't bigger than it needs\n    // to be.\n    const remnant = Buffer.alloc(stream.pos);\n    stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n    const doc = createChunkDoc(stream.id, stream.n, remnant);\n    // If the stream was aborted, do not write remnant\n    if (checkAborted(stream, callback)) {\n        return false;\n    }\n    stream.chunks.insertOne(doc, getWriteOptions(stream)).then(() => {\n        --stream.state.outstandingRequests;\n        checkDone(stream);\n    }, error => {\n        return __handleError(stream, error);\n    });\n    return true;\n}\nfunction checkAborted(stream, callback) {\n    if (stream.state.aborted) {\n        if (typeof callback === 'function') {\n            // TODO(NODE-3485): Replace with MongoGridFSStreamClosedError\n            callback(new error_1.MongoAPIError('Stream has been aborted'));\n        }\n        return true;\n    }\n    return false;\n}\n"]},"metadata":{},"sourceType":"script"}